name: Content Extraction

on:
  push:
    paths: ['data/pdfs/**']
  workflow_dispatch:

permissions:
  contents: write

concurrency:
  group: extract-${{ github.ref }}
  cancel-in-progress: false

jobs:
  find-changed-pdfs:
    runs-on: ubuntu-latest
    outputs:
      pdfs: ${{ steps.find-pdfs.outputs.pdfs }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 2

      - name: Find changed PDFs
        id: find-pdfs
        run: |
          # Get list of PDFs that changed in this push
          if [ "${{ github.event_name }}" = "push" ]; then
            # Compare with previous commit
            CHANGED_FILES=$(git diff --name-only HEAD~1 HEAD -- data/pdfs/*.pdf || echo "")
          else
            # Manual trigger - find all PDFs
            CHANGED_FILES=$(find data/pdfs -name "*.pdf" -type f | head -20)  # Limit for manual runs
          fi

          # Filter to PDF files and format as JSON array
          PDF_ARRAY="[]"
          if [ -n "$CHANGED_FILES" ]; then
            PDF_ARRAY=$(echo "$CHANGED_FILES" | jq -R -s 'split("\n") | map(select(. != ""))')
          fi

          echo "pdfs=$PDF_ARRAY" >> $GITHUB_OUTPUT
          echo "Found $(echo "$PDF_ARRAY" | jq length) PDFs to process"

  extract:
    runs-on: ubuntu-latest
    needs: find-changed-pdfs
    if: needs.find-changed-pdfs.outputs.pdfs != '[]'
    strategy:
      matrix:
        pdf: ${{ fromJson(needs.find-changed-pdfs.outputs.pdfs) }}
      max-parallel: 5  # Limit parallel extractions
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: Install dependencies
        run: pip install -e .

      - name: Extract document content
        run: |
          # Extract text and metadata from single PDF
          python -c "
          import sys
          sys.path.insert(0, 'src')
          from mandate_pipeline.extractor import extract_text, extract_operative_paragraphs, extract_title, extract_agenda_items, find_symbol_references
          from pathlib import Path
          import json

          pdf_path = Path('${{ matrix.pdf }}')
          if not pdf_path.exists():
              print(f'PDF not found: {pdf_path}')
              sys.exit(1)

          print(f'Extracting: {pdf_path.name}')

          # Extract content
          text = extract_text(pdf_path)
          paragraphs = extract_operative_paragraphs(text)
          title = extract_title(text)
          agenda_items = extract_agenda_items(text)
          symbol_refs = find_symbol_references(text)

          # Create extracted data structure
          extracted = {
              'symbol': pdf_path.stem.replace('_', '/'),
              'filename': pdf_path.name,
              'title': title,
              'text': text,
              'paragraphs': paragraphs,
              'agenda_items': agenda_items,
              'symbol_references': symbol_refs
          }

          # Save to extracted data file
          output_file = Path('data/extracted') / f'{pdf_path.stem}.json'
          output_file.parent.mkdir(parents=True, exist_ok=True)

          with open(output_file, 'w') as f:
              json.dump(extracted, f, indent=2)

          print(f'Extracted to: {output_file}')
          "

      - name: Commit extraction results
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          git add data/extracted/
          if git diff --staged --quiet; then
            echo "No extraction changes to commit"
          else
            git commit -m "chore: extract ${{ matrix.pdf }}"
            git pull --rebase origin main || true
            git push
          fi